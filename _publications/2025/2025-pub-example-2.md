---
title:          Cross-Modal Prototype Allocation: Unsupervised Slide Representation Learning via Patch-Text Contrast in Computational Pathology
date:           2025-03-26 00:01:00 +0800
selected:       true
pub:            "Arxiv"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-custom badge-secondary">Conference</span>'
pub_date:       "2025"

abstract: >-
  With the advancement of pathology FMs, WSI representation learning gains attention. Existing methods develop patch feature extractors and aggregation schemes but are task-specific, limiting generalizability. Unsupervised methods focus on visual modality, neglecting textual semantics. We propose ProAlign, a cross-modal unsupervised framework. It uses an LLM to generate descriptive text for WSI prototypes and introduces patch-text contrast. A parameter-free attention aggregation strategy forms unsupervised slide embeddings. Experiments on four datasets show ProAlign outperforms existing frameworks and matches some weakly supervised models.
  
cover:          assets/images/covers/proto.png
authors:
  - Yuxuan Chen*
  - Jiawen Li*
  - Jiali Hu*
  - Xitong Ling
  - Tian Guan
  - Anjia Han†
  - Yonghong He†
  
  links:
    Paper: https://arxiv.org/pdf/2503.20190
    
---


